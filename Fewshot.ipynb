{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhw9gO_YodH7",
        "outputId": "1d501862-6ac7-4571-ba2b-c108460774b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ib_bYYrs10Yy"
      },
      "outputs": [],
      "source": [
        "from os import walk\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "join = os.path.join"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, categories, root_dir, setSize, transform=None):\n",
        "        self.categories = categories\n",
        "        self.rootdir = root_dir\n",
        "        self.transform = transform\n",
        "        self.setSize = setSize\n",
        "    def __len__(self):\n",
        "        return self.setSize\n",
        "    def __getitem__(self, idx):\n",
        "        img1 = None\n",
        "        img2 = None\n",
        "        label = None\n",
        "        if idx % 2 == 0: \n",
        "            category = random.choice(self.categories)\n",
        "            img1Name = random.choice(category[1])\n",
        "            img2Name = random.choice(category[1])\n",
        "            img1 = Image.open(join(self.rootdir,join(category[0],img1Name)))\n",
        "            img2 = Image.open(join(self.rootdir,join(category[0],img2Name)))\n",
        "            label = 1.0\n",
        "        else: \n",
        "            category1, category2 = random.choice(self.categories), random.choice(self.categories)\n",
        "            while category1[0] == category2[0]:\n",
        "                category2 = random.choice(self.categories)\n",
        "            img1Name = random.choice(category1[1])\n",
        "            img2Name = random.choice(category2[1])\n",
        "            label = 0.0\n",
        "            img1 = Image.open(join(self.rootdir,join(category1[0],img1Name)))\n",
        "            img2 = Image.open(join(self.rootdir,join(category2[0],img2Name)))\n",
        "        if self.transform:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "        return img1, img2, torch.from_numpy(np.array([label], dtype=np.float32))     "
      ],
      "metadata": {
        "id": "SUqoJ1xo9PG3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataSize = 10000 \n",
        "TRAIN_PCT = 0.8 \n",
        "train_size = int(dataSize * TRAIN_PCT)\n",
        "val_size = dataSize - train_size\n",
        "\n",
        "transformations = transforms.Compose(\n",
        "    [transforms.Resize((105,105)),\n",
        "        transforms.ToTensor()]) \n",
        "root_dir = '/content/drive/MyDrive/Task/Egg/oneshot_data'\n",
        "k= []\n",
        "for folder in os.listdir(root_dir):\n",
        "     if not folder.startswith('.'):\n",
        "        k.append([folder, os.listdir(join(root_dir , folder))])\n",
        "omniglotDataset = TrainDataset(k, root_dir, dataSize, transformations)\n",
        "train_set, val_set = random_split(omniglotDataset, [train_size, val_size])\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, num_workers=16)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=1, num_workers=16, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EADdmSLApjGa",
        "outputId": "99d2c672-3f79-4b0f-b2b3-de0ca169240c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 64, 10) \n",
        "        self.conv2 = nn.Conv2d(64, 128, 7)  \n",
        "        self.conv3 = nn.Conv2d(128, 128, 4)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 4)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
        "        self.fcOut = nn.Linear(4096, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def convs(self, x):\n",
        "\n",
        "        \n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        x = F.max_pool2d(x, (2,2))\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "\n",
        "        x = F.max_pool2d(x, (2,2))\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "        x = F.max_pool2d(x, (2,2))\n",
        "\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.convs(x1)\n",
        "        x1 = x1.view(-1, 256 * 6 * 6)\n",
        "        x1 = self.sigmoid(self.fc1(x1))\n",
        "\n",
        "        \n",
        "        x2 = self.convs(x2)\n",
        "        x2 = x2.view(-1, 256 * 6 * 6)\n",
        "        x2 = self.sigmoid(self.fc1(x2))\n",
        "\n",
        "        x = torch.abs(x1 - x2)\n",
        "        x = self.fcOut(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ORGDzrjno8jT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "siameseBaseLine = Net()\n",
        "siameseBaseLine = siameseBaseLine.to(device)\n"
      ],
      "metadata": {
        "id": "621Jrj0_qIkU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(save_path, model, optimizer, val_loss):\n",
        "    if save_path==None:\n",
        "        return\n",
        "    save_path = save_path \n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'val_loss': val_loss}\n",
        "\n",
        "    torch.save(state_dict, save_path)\n",
        "\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(model, optimizer):\n",
        "    save_path = f'siameseNet-batchnorm50.pt'\n",
        "    state_dict = torch.load(save_path)\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
        "    val_loss = state_dict['val_loss']\n",
        "    print(f'Model loaded from <== {save_path}')\n",
        "    \n",
        "    return val_loss"
      ],
      "metadata": {
        "id": "xDr_lSmWqTDi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(siameseBaseLine.parameters(), lr = 0.0006)\n",
        "num_epochs = 50\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "save_path = '/content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt'"
      ],
      "metadata": {
        "id": "phTfMD2jqi45"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, val_loader, num_epochs, criterion, save_name):\n",
        "    best_val_loss = float(\"Inf\") \n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    cur_step = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "        print(\"Starting epoch \" + str(epoch+1))\n",
        "        for img1, img2, labels in train_loader:\n",
        "            \n",
        "\n",
        "            img1 = img1.to(device)\n",
        "            img2 = img2.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(img1, img2)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "        \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        \n",
        "        val_running_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for img1, img2, labels in val_loader:\n",
        "                img1 = img1.to(device)\n",
        "                img2 = img2.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(img1, img2)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_running_loss += loss.item()\n",
        "        avg_val_loss = val_running_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        \n",
        "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.8f}'\n",
        "            .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            save_checkpoint(save_name, model, optimizer, best_val_loss)\n",
        "    \n",
        "    print(\"Finished Training\")  \n",
        "    return train_losses, val_losses  \n"
      ],
      "metadata": {
        "id": "XeD1NoBZqXGb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses = train(siameseBaseLine, train_loader, val_loader, num_epochs, criterion, save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLYrN7zKqnh6",
        "outputId": "f9a0e538-ba1f-4ffa-d181-516ef22e9bb5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "Epoch [1/50],Train Loss: 0.2723, Valid Loss: 0.14103082\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 2\n",
            "Epoch [2/50],Train Loss: 0.0972, Valid Loss: 0.08534995\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 3\n",
            "Epoch [3/50],Train Loss: 0.0633, Valid Loss: 0.07765579\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 4\n",
            "Epoch [4/50],Train Loss: 0.0544, Valid Loss: 0.07426170\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 5\n",
            "Epoch [5/50],Train Loss: 0.0451, Valid Loss: 0.06892415\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 6\n",
            "Epoch [6/50],Train Loss: 0.0295, Valid Loss: 0.07679268\n",
            "Starting epoch 7\n",
            "Epoch [7/50],Train Loss: 0.0260, Valid Loss: 0.06444442\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 8\n",
            "Epoch [8/50],Train Loss: 0.0246, Valid Loss: 0.06378427\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 9\n",
            "Epoch [9/50],Train Loss: 0.0252, Valid Loss: 0.06373819\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 10\n",
            "Epoch [10/50],Train Loss: 0.0199, Valid Loss: 0.06250771\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 11\n",
            "Epoch [11/50],Train Loss: 0.0219, Valid Loss: 0.05649988\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 12\n",
            "Epoch [12/50],Train Loss: 0.0203, Valid Loss: 0.05727750\n",
            "Starting epoch 13\n",
            "Epoch [13/50],Train Loss: 0.0127, Valid Loss: 0.05364205\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 14\n",
            "Epoch [14/50],Train Loss: 0.0152, Valid Loss: 0.06070657\n",
            "Starting epoch 15\n",
            "Epoch [15/50],Train Loss: 0.0139, Valid Loss: 0.05890231\n",
            "Starting epoch 16\n",
            "Epoch [16/50],Train Loss: 0.0117, Valid Loss: 0.05710048\n",
            "Starting epoch 17\n",
            "Epoch [17/50],Train Loss: 0.0110, Valid Loss: 0.05610395\n",
            "Starting epoch 18\n",
            "Epoch [18/50],Train Loss: 0.0122, Valid Loss: 0.05775015\n",
            "Starting epoch 19\n",
            "Epoch [19/50],Train Loss: 0.0093, Valid Loss: 0.04859730\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 20\n",
            "Epoch [20/50],Train Loss: 0.0073, Valid Loss: 0.05342571\n",
            "Starting epoch 21\n",
            "Epoch [21/50],Train Loss: 0.0106, Valid Loss: 0.05750972\n",
            "Starting epoch 22\n",
            "Epoch [22/50],Train Loss: 0.0116, Valid Loss: 0.05540580\n",
            "Starting epoch 23\n",
            "Epoch [23/50],Train Loss: 0.0122, Valid Loss: 0.05116961\n",
            "Starting epoch 24\n",
            "Epoch [24/50],Train Loss: 0.0096, Valid Loss: 0.04883834\n",
            "Starting epoch 25\n",
            "Epoch [25/50],Train Loss: 0.0085, Valid Loss: 0.04990028\n",
            "Starting epoch 26\n",
            "Epoch [26/50],Train Loss: 0.0062, Valid Loss: 0.05232885\n",
            "Starting epoch 27\n",
            "Epoch [27/50],Train Loss: 0.0083, Valid Loss: 0.04758929\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 28\n",
            "Epoch [28/50],Train Loss: 0.0071, Valid Loss: 0.05324196\n",
            "Starting epoch 29\n",
            "Epoch [29/50],Train Loss: 0.0083, Valid Loss: 0.04844272\n",
            "Starting epoch 30\n",
            "Epoch [30/50],Train Loss: 0.0093, Valid Loss: 0.05289345\n",
            "Starting epoch 31\n",
            "Epoch [31/50],Train Loss: 0.0092, Valid Loss: 0.05233920\n",
            "Starting epoch 32\n",
            "Epoch [32/50],Train Loss: 0.0081, Valid Loss: 0.04910126\n",
            "Starting epoch 33\n",
            "Epoch [33/50],Train Loss: 0.0090, Valid Loss: 0.04494127\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 34\n",
            "Epoch [34/50],Train Loss: 0.0109, Valid Loss: 0.04739464\n",
            "Starting epoch 35\n",
            "Epoch [35/50],Train Loss: 0.0074, Valid Loss: 0.04674494\n",
            "Starting epoch 36\n",
            "Epoch [36/50],Train Loss: 0.0100, Valid Loss: 0.04929603\n",
            "Starting epoch 37\n",
            "Epoch [37/50],Train Loss: 0.0067, Valid Loss: 0.04543887\n",
            "Starting epoch 38\n",
            "Epoch [38/50],Train Loss: 0.0070, Valid Loss: 0.04888638\n",
            "Starting epoch 39\n",
            "Epoch [39/50],Train Loss: 0.0101, Valid Loss: 0.04203068\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 40\n",
            "Epoch [40/50],Train Loss: 0.0069, Valid Loss: 0.04902071\n",
            "Starting epoch 41\n",
            "Epoch [41/50],Train Loss: 0.0070, Valid Loss: 0.04061547\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 42\n",
            "Epoch [42/50],Train Loss: 0.0067, Valid Loss: 0.04231016\n",
            "Starting epoch 43\n",
            "Epoch [43/50],Train Loss: 0.0077, Valid Loss: 0.04443637\n",
            "Starting epoch 44\n",
            "Epoch [44/50],Train Loss: 0.0063, Valid Loss: 0.03965430\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 45\n",
            "Epoch [45/50],Train Loss: 0.0052, Valid Loss: 0.04410759\n",
            "Starting epoch 46\n",
            "Epoch [46/50],Train Loss: 0.0074, Valid Loss: 0.04149302\n",
            "Starting epoch 47\n",
            "Epoch [47/50],Train Loss: 0.0076, Valid Loss: 0.04436484\n",
            "Starting epoch 48\n",
            "Epoch [48/50],Train Loss: 0.0095, Valid Loss: 0.04276088\n",
            "Starting epoch 49\n",
            "Epoch [49/50],Train Loss: 0.0099, Valid Loss: 0.03850061\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Starting epoch 50\n",
            "Epoch [50/50],Train Loss: 0.0069, Valid Loss: 0.03794838\n",
            "Model saved to ==> /content/drive/MyDrive/Task/Egg/model/siameseNet-batchnorm50.pt\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/drive/MyDrive/Task/Egg/oneshot_data/Vi/531.jpg')\n",
        "img = TF.resize(img,(105,105))\n",
        "img = TF.to_tensor(img)"
      ],
      "metadata": {
        "id": "M-5zV1NGq0IV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.unsqueeze(0).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOorEtZt40Hf",
        "outputId": "83a05b0f-3a96-4015-bf60-97adb9f7f353"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 105, 105])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Average(lst):\n",
        "    return sum(lst) / len(lst)"
      ],
      "metadata": {
        "id": "AAVIe80_7Eox"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  siameseBaseLine.eval()\n",
        "  mainImg = Image.open('/content/drive/MyDrive/Task/Egg/1/Screenshot 2023-05-17 161142.png')\n",
        "  mainImg = mainImg.convert('RGB')      \n",
        "  mainImg = TF.resize(mainImg,(105,105))\n",
        "  mainImg = TF.to_tensor(mainImg).to(device).unsqueeze(0)\n",
        "  root = '/content/drive/MyDrive/Task/Egg/oneshot_data'\n",
        "  result = {\n",
        "  }\n",
        "  for champ in os.listdir(root):\n",
        "    avr = []\n",
        "    for name in os.listdir(join(root,champ)):\n",
        "      img2 = Image.open(join(root,join(champ,name)))\n",
        "      img2 = TF.resize(img2,(105,105))\n",
        "      img2 = TF.to_tensor(img2)\n",
        "      img2 = img2.to(device).unsqueeze(0)\n",
        "      output = siameseBaseLine(mainImg,img2)\n",
        "      avr.append(output)\n",
        "    result[champ] = Average(avr)\n",
        "\n",
        "max_value = max(result, key=result.get)\n",
        "print(max_value)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sfdtXph5Y6n",
        "outputId": "82cfda62-a5d6-4860-d713-56b5105d4cf8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Malphite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ctvV1lo-1iX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}